Please comment here!

I agree with you that the bus question in class is a suitable problem for explaining the three levels of human cognitive process. And your own example of examinations is really funny that I have learnt more about them. Hope to read more humorous examples in your further blog.

As I learner of go, I really respect to AlphaGo. In the last few weeks, AlphaGo Zero is developed and win the previous version of AlphaGo. AlphaGo Zero plays the game totally different from human’s experience. Human learns Go from the physical layer, to semantic layer. AlphaGo also starts from the human previous chess playbook. However, AlphaGo Zero learns Go from the digital layer directly. Therefore, AlphaGo Zero is more powerful than AlphaGo.

I really appreciate that you provide many examples from our daily life to explain your points such as iPhone X and AlphaGo. But my point is different from yours. From the lecture, we learned that digital agents study from abstraction to embodiment. My understanding is that digital agents can digest digital information more easily. And then they can learn semantic information. Perception and cognition of physical information is the hardest part. You conclude that AI is the integration of three layers, while I think AI will only process digital information at last. Take AlphaGo Zero as an example, it beat AlphaGo. It does not learn from human’s experience, however, it learns by itself. After bypassing semantic information, it performs better anyway. Maybe this suggests that human can also learn from the machine. Because digital agents are always in the most abstract part.

Interesting article you have here. NLP just like all the other AI branches has developed a lot in the past couple of year as you mentioned, which is evident from all the digital assistants out there in the market. However, I wouldn’t rush into saying they have changed our lives. At least for now. The problem is, there is a lot of ambiguity in human speech. We don’t even notice it, but when we talk, we imply a lot of things, that maybe, are obvious for other people, but not for computers. NLP has only started teaching the systems to correctly interpret vague elements of our speech, however, I believe, it’s still not enough for smooth user experience. This is why all the digital assistants are not used much, but instead are more of a fun feature rather than actually necessary and deal breaking. After all, if iPhone wouldn’t have Siri, I don’t think any iPhone user would move onto an Android phone because of that.

Despite what I said, I want to mention that the progress is noticeable. Maybe it’s just me, but now, when you google something, the answers you get are more accurate than they were multiple years ago. I don’t remember when the last time I had to go to the second page in order to find an answer. And what’s more interesting, from my personal experience, this remains true when my search consists of the whole sentence. I really feel like google understand me better than it used before. I do, believe it’s gonna have a great impact on our lives very soon considering how fast the progress goes, but not just yet.

I agree with you on the scepticism about NLP reaching the level where it could completely understand semantics behind our speech. Linguistics and psychology stands behind what we say, what we mean and how these 2 factors are related, so yea, without fully understanding the 2 factors, we won’t be able to make NLP understand humans to full. However, NLP progress could be a result of more general AI development. After all, all we need is to teach AI to learn and understand, and then Natural Language Processing will happen automatically without any input. The machines will teach themselves. This is essentially what humans do. We are already pre-programmed to learn. We don’t specifically teach kids how to speak or understand what we tell them. It happens automatically, through experience.

I want to believe this will happen in relatively near future (in our lifetime at least). Here’s an interesting study which shows why it there’s a chance it will happen before 2200: https://nickbostrom.com/papers/survey.pdf

I think that the development of AI must involve NLP in the future. Take Siri as an example, at first, it can only respond to simple question like opening some apps or making phone call. But now, when we ask some naive question, Siri will give some fun respond just like human, and there are many video about how people discovering different fun responds of Siri on the net. When we can have a more advanced NLP, and can let the computer break down a process like human, such as build up a cognition for computer to read a passage, we can have a big improvement in AI.

This is the best topic I read today.

As Hinton’s model of linguistics structure tell us we can gain an idea of languages from raw spoken sounds to the complexities of meanings influenced by the context.
The NLP is important for us to future develop AI and the linguistics. Like the AlphaGo in Sam’s blog, it is also develop in the simple bot and it learns deeply by time to time, and now comes the world No.1 player.

