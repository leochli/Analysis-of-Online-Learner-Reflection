AI for sensing everything — the integration of information models

To understand information hierarchically, we have learnt the models and layers of information. They are physical, semantic and digital information respectively. For example, perception and cognition belongs to the physical information system. They are of the core mechanisms for our body to receive information from the environment and change very slowly. For semantic information, it refers to information as semantic content that conveys meaning, such as languages, icons, index etc. In regard to digital information, they’re usually the communicating method among machines like digital signals, digital waves etc.

Today AI is among the hottest topics in the human society. What is AI? Some of the most well-known facts are deep blue beats G. Kasparov in 1997, robot shows how to solve Rubik’s cube and most recently, AlphaGo beats Lee Sedol on March 12th 2016. Actually, today (20th October 2017), Google’s AlphaGo Zero again, beats AlphaGo with 100:0.

The game of Go is quite an appropriate example for semantic information and our cognition system. Our brain gathers data about the game board through eyes. It then works with abstract representations of what is sensed, such as the game rules, so that we know what’s going on the board. The next step, our brain will processes the representational data where the game level varies from person to person. Finally, the brain translates the information to instructions to our body. That is, we make our decision to go.

In AI’s beating previous world champion, it demonstrates an extraordinary ability to process the representational data, in this case which is the semantic information. Different from our cognition system, the AI would translate the semantic information to digital information and process the digital signals. Also, to get the semantic information, it has to perceive the information through vision. Nowadays computer vision has been so advanced that it can achieve very high accuracy in image and video classification. When it comes to human face recognition, the deep learning approach is even more accurate than human eyes, since it could analyse the face attributes and landmarks. Think of iPhone X! That’s why Apple would allow face recognition to take place of fingerprint recognition.

From the previous example, the AI manages to convert physical information and semantic information to digital information, which it can understand and process. Now that we already have  Siri to understand our words, deep learning method in computer vision to realise self-driving. It can be anticipated that AI would become available to translate more and more physical and semantic information in the real world. The day when AI could integrate all the three information models is the day when AI can sense everything!